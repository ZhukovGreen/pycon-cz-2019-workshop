{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Reading data\n",
    "\n",
    "This notebook is the second part of the collection devoted to the pandas library.\n",
    "\n",
    "It explores the ways how data can be imported into DataFrames. \n",
    "\n",
    "More details can be found in the official documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-sql\n",
    "\n",
    "Most of the functions for reading data are named `pandas.read_XXX`, where XXX is the format used. We will go through the most commonly used ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesssary import evil\n",
    "\n",
    "import jupy_helpers\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List function for input in pandas.\n",
    "\n",
    "print(\"\\n\".join(method for method in dir(pd) if method.startswith(\"read_\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV\n",
    "\n",
    "Nowadays, a lot of data comes in the textual Comma-separated values format (CSV).\n",
    "Although not properly standardized, it is the de-facto standard for files that are not\n",
    "huge and are meant to be read by human eyes too.\n",
    "\n",
    "Let's read the ratings of several (hundred) movies from Rotten Tomatoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%head ../data/rotten_tomatoes_top_movies_2019-01-15.csv 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df = pd.read_csv(\"../data/rotten_tomatoes_top_movies_2019-01-15.csv\")\n",
    "rotten_df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic data type parsing automatically converts columns to appropriate types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the CSV input does not work out of the box. Although pandas automatically understands and reads zipped files,\n",
    "it usually does not automatically infer the file format - for details, see the `read_csv` documentation here: \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/title.basics.tsv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...in this case, the CSV file does not use commas to separate values. Therefore, we need to specify a few more arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t')\n",
    "imdb_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed the `\\N` endYear values?\n",
    "\n",
    "**Exercise:** Use `na_values` argument to mark `\\N` as a null (missing) value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "# imdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t', na_values=...)\n",
    "imdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t', na_values=\"\\\\N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert pd.isna(imdb_titles.loc[0, 'endYear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Excel\n",
    "\n",
    "Let's read the list of best movies by genre from Guardian (a bit old, written in 2010).\n",
    "\n",
    "![Screenshot](guardian-best-horrors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(\"../data/guardian-greatest_films_of_all_time.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmmph... Pandas parsed just the first spreadsheet. Let's see what are the options. If in doubt, look in the documentation:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/io.html#excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.io.excel.ExcelFile(\"../data/guardian-greatest_films_of_all_time.xlsx\")\n",
    "xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx.parse(\"HORROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "#crimes =...                    # Find the table of crime movies\n",
    "#tenth_best = crimes.loc[...]   # Find the 10-th best crime movie\n",
    "#movie_name = ...               # Get the name of the movie\n",
    "\n",
    "#movie_name\n",
    "\n",
    "crimes = pd.read_excel(\"../data/guardian-greatest_films_of_all_time.xlsx\", \"CRIME\")\n",
    "tenth_best = crimes.loc[9]\n",
    "movie_name = tenth_best[\"Film\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert movie_name[7:9] == \"la\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies = pd.read_json(\"../data/wikipedia-movies.json\")\n",
    "wiki_movies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SQL\n",
    "\n",
    "On its own, pandas can read SQLite databases. If **sqlalchemy** package is installed, pandas allows to access\n",
    "any database that is supported by the former library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires sqlalchemy\n",
    "award_table = pd.read_sql(\"awards\", con='sqlite:///../data/awards.sqlite')\n",
    "award_table.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to pass a SQL query too (no sqlalchemy necessary with sqlite3)\n",
    "import sqlite3\n",
    "connection = sqlite3.connect(\"../data/awards.sqlite\")\n",
    "\n",
    "awards2017 = pd.read_sql(\"SELECT * FROM awards WHERE Year=2017\", con=connection)\n",
    "awards2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HTML\n",
    "\n",
    "Pandas is able to scrape data from tables embedded in web pages using the `read_html` function.\n",
    "This might or might not bring you good results and probably you will have to tweak your\n",
    "data frame manually. But it is a good starting point - much better than being forced to parse\n",
    "the HTML ourselves!\n",
    "\n",
    "Let's download a list of highest-grossing films from wikipedia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\")\n",
    "type(tables), len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the page really contain 95 tables? The number is quite high and we must check which of the tables\n",
    "are meaningful and which are not. We are mostly interested in the first displayed one.\n",
    "\n",
    "**Exercise:** Find **i** to obtain the right table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "# i = ...\n",
    "\n",
    "i = 0\n",
    "table = tables[i]\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert table.iloc[2][\"Title\"] == \"Titanic\"  # 3rd msot grossing movie ever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV\n",
    "\n",
    "Pandas is able to write to many various formats but the usage is similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_table.to_csv(\"awards.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%head awards.csv 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write SQL\n",
    "\n",
    "Load all data for the rest of the workshop and save as into local sqlite database.\n",
    "\n",
    "**Note**: This is an important step. We will use the data in the later phases.\n",
    "If in doubt, refer to the \"solution\" version of this file (TODO: link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_data = dict(\n",
    "    imdb_titles = imdb_titles,\n",
    "    imdb_ratings = pd.read_csv('../data/title.ratings.tsv.gz', sep='\\t'),\n",
    "    boxoffice = pd.read_csv('../data/boxoffice_march_2019.csv.gz'),\n",
    "    rotten_tomatoes = rotten_df,\n",
    "    awards = award_table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = 'sqlite:///./workshop_data.sqlite'\n",
    "\n",
    "for name, df in workshop_data.items():\n",
    "    df.to_sql(name, con, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When done with this notebook, we suggest that you shutdown the kernel to free the memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
